---
title: "Proposal"
author: "Paul Crowley and Patric Platts"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction

Companies frequently receive numerous complaints. However, the way they resolve these issues—and the speed at which they do so—shapes individual's opinion of the company. To ensure complaints are resolved efficiently and effectively, they must be directed to the appropriate department for handling. The data supplied for analysis contained only the complaints and the departments assigned to resolve them. Most companies hire specialists to sort through complaints and direct them to the appropriate departments. However, with over 1.5 million complaints to process, this can become time-consuming, potentially leading to a decline in customer satisfaction. To improve speed, machine learning techniques can be used to determine the appropriate department for each complaint based on the language and keywords in the complaint.

```{r, include=FALSE}
library(tidytext)
library(stopwords)

dat = read.csv('CompanyComplaints.csv')
tokens = sapply(dat$Complaint,tokenize_words)

tokens <- dat %>%
  unnest_tokens(word, Complaint) %>%
  filter(!word %in% stopwords("en")) %>% # Remove stop words
  filter(!word %in% c("company", "complaint", "product", "customer")) %>% # Additional custom stop words
  count(Department, word, sort = TRUE) 

top_words <- tokens %>%
  group_by(Department) %>%
  slice_max(n, n = 8) %>%
  ungroup()

name_mapping <- c(
  "Debt collection" = "Debt Collection",
  "Credit reporting, credit repair services, or other personal consumer reports" = "Credit Reporting",
  "Money transfer, virtual currency, or money service" = "Money Services",
  "Mortgage" = "Mortgage",
  "Student loan" = "Student Loan",
  "Checking or savings account" = "Bank Accounts",
  "Credit card or prepaid card" = "Credit Cards",
  "Payday loan, title loan, or personal loan" = "Personal Loans",
  "Vehicle loan or lease" = "Vehicle Loan"
)

top_words <- top_words %>%
  mutate(Department = name_mapping[Department])
```
```{r, echo=FALSE, fig.align='center'}
ggplot(top_words, aes(x = reorder(word, n), y = n / 1000, fill = Department)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ Department, scales = "free") +
  labs(title = "Top 8 Words by Department",
       x = "Words",
       y = "Frequency (Thousands)") +
  theme_minimal()
```

## FIGURE HERE
Based on the data in the bar charts, there seem to be some censored words that are very common across all department complaints. Howeverm these may not be the most helpful words given their prevalence across all departments. The model may need to find words that are both common and more unique to the correct department.

The goals of the analysis are to identify key attributes of the text such as words, phrases, or symbols that are most useful in routing complaints. We can then assess the accuracy of the model and identify common mistakes the model could make. The model would then be ready to use on new complaints. A key obstacle to developing a model is the absence of traditional explanatory variables, requiring the creation of features. The accuracy of classifications will depend on the utility of variables we create from the data. The task is further complicated because textual data often includes noise such from typos and ambiguous language. Additionally, complaints directed to similar departments might share extensive overlap in language, leading to common misclassifications. Without addressing these issues, the model will experience reduced accuracy and may not be practically useful for future use.

One challenge in the dataset is that the complaints are written as sentences or paragraphs, making them unstructured and detailed descriptions of the issues. Since the complaints are strings and none are identical, they cannot be converted into categorical factors directly. This also prevents the complaints from being classified based on any common criteria for each group, resulting in unsorted complaints. To address this issue, the complaints are parsed, and specific words are extracted and counted from each complaint to help determine the appropriate department for resolution. This approach enables the application of various machine learning techniques to identify the department to which each complaint belongs. The goal of this analysis is to accurately classify complaints into their corresponding departments, identify key words or symbols that assist in the classification, determine which departments are commonly confused, and ensure the ability to classify new complaints not included in the training data for the machine learning methods.

### Methodology

# Method 1

The K-Nearest Neighbors (KNN) model is a straightforward machine learning algorithm that can be used for multi-class text classification by identifying the most similar examples in the data. The features were generated using TF-IDF (Term Frequency-Inverse Document Frequency), which emphasizes terms that are more unique for classification. TF-IDF can emphasize keywords that are more relevant to specific departments by down-weighting common terms used across all departments. This simultaneously addresses the need for engineered features and the need to identify features uniquely useful for classifying complaints to a particular department. Stopwords are useful for accounting for common articles and other words that are not useful for classification. The KNN algorithm is very flexible and requires no distribution or independence assumptions.

This model is advantageous for its simplicity, ability to account for similar language used across departments, and for its flexibility to be used for any new text data. However, the model can be prone to overfitting, especially with high dimensional feature space. The algorithm can also be more computationally expensive than alternative classification methods. 

# Method 2

The second method that is proposed to be ...
